{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Устанавливаем scholarly.\n",
        "\n"
      ],
      "metadata": {
        "id": "h2LjwHQMv4dS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scholarly"
      ],
      "metadata": {
        "id": "gDSnNxML4viZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scholarly import scholarly\n",
        "from scholarly import ProxyGenerator\n",
        "import os\n",
        "import csv"
      ],
      "metadata": {
        "id": "tmI6wbzt44LK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Так как Google Scholar позволяет выкачивать ограниченное количество данных за сутки, нам будет необходимо с каждым новым запросом обновлять прокси."
      ],
      "metadata": {
        "id": "Mz-m83vRwMT_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pg = ProxyGenerator()\n",
        "scholarly.use_proxy(pg, pg)"
      ],
      "metadata": {
        "id": "sXSQ-CtI4tVv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Мы будем производить поиск по ID каждго автора, чтобы избежать проблемы с полными тёзками. ID есть на странице автора в Google Scholar. В список author_ids записываем интересующие нас ID."
      ],
      "metadata": {
        "id": "cfSj74djxJkh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "r3BhdvEu4sUt"
      },
      "outputs": [],
      "source": [
        "author_ids = ['D1HB8BAAAAAJ']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Заводим словарь, куда будем сохранять нужную нам информацию - имя автора, название публикации, год публикации, количество соавторов, имена соавторов.\n",
        "Заводим файл в формате csv, где в качестве заголовков столбцов будут выступать ключи из словаря.\n",
        "\n",
        "Для каждого автора из списка author_ids с помощью функции scholarly.fill() ищем публикации. В переменные name и publications записываем имя и публикации.\n",
        "Сравниваем количество уже имеющихся публикаций с количеством публикаций в google scholar, если имеющихся больше или столько же, переходим к следующему автору.\n",
        "В цикле смотрим каждую публикацию. Если публикация уже есть в csv файле, пропускаем её. С помощью scholarly.fill() получаем данные о публикации. В словарь pub_res сохраняем данные об имени автора, названии публикации, количестве соавторов, именах соавторов и годе публикации.\n",
        "Информацию из словаря записываем в csv файл."
      ],
      "metadata": {
        "id": "4DtNEHFoxrLO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keys = ['author','title','pub_year','number_of_co_authors','co_authors']\n",
        "\n",
        "output_file =  open('publications.csv', 'a', newline='')\n",
        "dict_writer = csv.DictWriter(output_file, keys)\n",
        "if os.path.getsize('publications.csv') == 0:\n",
        "    dict_writer.writeheader()\n",
        "    output_file.flush()\n",
        "dict_reader = csv.DictReader(open('publications.csv', newline=''), keys)\n",
        "csv_reader = [row for row in dict_reader]\n",
        "\n",
        "\n",
        "\n",
        "for id in author_ids:\n",
        "    author = scholarly.search_author_id('D1HB8BAAAAAJ')\n",
        "    author =  scholarly.fill((author),sections = ['publications'])\n",
        "    name = author['name']\n",
        "    pubs = author['publications']\n",
        "    author_pubs_in_file = [row for row in csv_reader if row['author'] == name]\n",
        "    num_author_pubs_in_file = len(author_pubs_in_file)\n",
        "    if num_author_pubs_in_file >= len(author['publications']): continue\n",
        "    i = 0\n",
        "    for pub in pubs:\n",
        "        if i < num_author_pubs_in_file:\n",
        "            i += 1\n",
        "            continue\n",
        "        pub = scholarly.fill(pub)\n",
        "        if len([x for x in author_pubs_in_file if x['title'] == pub['bib']['title']]) > 0 : continue\n",
        "        pub_res = {\n",
        "            \"author\":name,\n",
        "            \"title\":pub['bib']['title']\n",
        "            }\n",
        "\n",
        "        if 'author' in pub['bib']:\n",
        "            pub_res['number_of_co_authors'] = len(pub['bib']['author'].split(' and ')) - 1\n",
        "            pub_res['co_authors'] = pub['bib']['author']\n",
        "        else:\n",
        "            pub_res[\"number_of_co_authors\"] = ''\n",
        "\n",
        "        if 'pub_year' in pub['bib']:\n",
        "            pub_res['pub_year'] = pub['bib']['pub_year']\n",
        "        else:\n",
        "            pub_res['pub_year'] = ''\n",
        "\n",
        "        dict_writer.writerows([pub_res])\n",
        "        output_file.flush()"
      ],
      "metadata": {
        "id": "cV2yloee4z6r"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GUuaM7vlsuco"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}